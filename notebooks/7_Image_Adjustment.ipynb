{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image adjustment: transforming image content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most functions for manipulating color channels are found in the submodule `skimage.color`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion between color models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color images can be represented using different color spaces. One of the most common color spaces is the RGB space, where an imsge has red, green and blue channels. However, other color modelss are widely used, such as the HSV color model, where hue, saturation and value are independent channels, or the CMYK model used for printing.\n",
    "\n",
    "`skimage.color` provides utility functions to convert images to and from different color spaces. Integer-tyoe arrays can be transformed to floating-point type by the conversion operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.83333333, 0.60784314, 1.        ]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bright saturated red\n",
    "red_pixel_rgb = np.array([[[255, 0, 0]]], dtype=np.uint8)\n",
    "color.rgb2hsv(red_pixel_rgb)\n",
    "\n",
    "#Â darker saturated blue\n",
    "dark_blue_pixel_rgb = np.array([[[0, 0, 100]]], dtype=np.uint8)\n",
    "color.rgb2hsv(dark_blue_pixel_rgb)\n",
    "\n",
    "# less saturated pink\n",
    "pink_pixel_rgb = np.array([[[255, 100, 255]]], dtype=np.uint8)\n",
    "color.rgb2hsv(pink_pixel_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion from RGBA to RGB - Removing alpha channel through alpha blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting an RGBA image to an RGB image by alpha blending it with a background is realized with `rgba2rgb()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgba2rgb\n",
    "from skimage import data\n",
    "img_rgba = data.logo()\n",
    "img_rgb = rgba2rgb(img_rgba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion between color and gray values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting an RGB image to a grayscale image is realized with `rgb2gray()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "from skimage import data\n",
    "img = data.astronaut()\n",
    "img_gray = rgb2gray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rgb2gray()` uses a non-uniform weighting of color channels, because of the different sensitivity to the human eye to different colors. Therefore, such a weighting ensures **luminance preservation** from RGB to grayscale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7154]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_pixel = np.array([[[255, 0, 0]]], dtype=np.uint8)\n",
    "color.rgb2gray(red_pixel)\n",
    "\n",
    "green_pixel = np.array([[[0, 255, 0]]], dtype=np.uint8)\n",
    "color.rgb2gray(green_pixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting a grayscale image to RGB with `gray2rgb()` simply duplicates the gray values over the three color channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An inverted image is also called complementary image. For binary images, True values become False and conversely. For grayscale images, pixel values are replaced by the difference of the maximum value of the data type and the actual value. For RGB images, the same operation is done for each channel. This operation can be achieved with `skimage.util.invert()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import util\n",
    "img = data.camera()\n",
    "inverted_img = util.invert(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Painting images with labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`label2rgb()` can be used to superimpose colors on a grayscale image using an array of labels to encode the reion to be represented with the same color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrast and exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image pixel can take values determined by the `dtype` of the image (see **Image data types and what they mean**), such as 0 to 255 for `uint8` image or `[0,1]` for floating-point images. However, most images either have a narrower range of values (because of poor contrast), or have most pixel values concentrated in a subrange of the accessible values. `skimage.exposure` provides functions that spread the intensity values over a larger range. \n",
    "\n",
    "A first class methods compute a nonlinear function of the intensity, that is independent of the pixel values of a specific image. Such methods are often used for correcting a known non-linearity of sensors, or receptors such as the human eye. A well-known example if **Gamma correction**, implemented in `adjust_gamma()`.\n",
    "\n",
    "Other methods re-distribute pixel values according to the **histogram** of the image. The histogram of pixel values is computed with `skimage.exposure.histogram()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 0, 1], dtype=int64), array([1, 2, 3]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage import exposure\n",
    "image = np.array([[1, 3], [1, 1]])\n",
    "exposure.histogram(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`histogram()` returns the number of pixels for each value bin, and the centers of the bins. The behavior of `histogram()` is therefore slightly different from the one of `numpy.histogram()`, which returns the boundaries of the bins.\n",
    "\n",
    "The simplest contrast enhancement `rescale_intensity()` consists in streching pixel values to the whole allowed range, using a linear transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage import exposure\n",
    "text = data.text()\n",
    "text.min(), text.max()\n",
    "\n",
    "better_contrast = exposure.rescale_intensity(text)\n",
    "better_contrast.min(), better_contrast.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if an image uses the whole value range, sometimes there is very little weigh at the ends of the value range.  In such a case, clipping pixel values using percentiles of the image improves the contrast (at the expense of some loss of information, because some pixels are saturated by this operation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "moon = data.moon()\n",
    "v_min, v_max = np.percentile(moon, (0.2, 99.8))\n",
    "v_min, v_max\n",
    "\n",
    "better_contrast = exposure.rescale_intensity(\n",
    "                                    moon, in_range=(v_min, v_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fundtion `equalize_hist()` maps the cumulative distribution function (cdf) of pixdel values onto a linear cdf, ensuring that all parts of the value range are equally represented in the image. As a result, details are enhanced in large regions with poor contrast. As a further refinement, histogram equalization can be performed in subregions "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
